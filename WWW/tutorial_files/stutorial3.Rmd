Psych 252: R Tutorial Module 3
========================================================

Based on notes by Paul Thibodeau (2009) and revisions by the Psych 252 instructors in 2010 and 2011

Expanded in 2012 by Mike Frank, Benoit Monin and Ewart Thomas

Converted to [R Markdown](http://www.rstudio.com/ide/docs/r_markdown) format and further expanded in 2013 by Steph Gagnon.

2014 TAs: Rebecca Carey, Caitie Handron, Kara Weisman, Daniel Hawthorne, Steph Gagnon, Alyssa Fu, Kevin Mickey

Performing t-tests in R
-----------------------

The *t-test* allows us to test a **null hypothesis ($H_0$)** about population means. For instance, if we are interested in whether two populations are different, we can test the $H_0$ that the mean of population 1 is equal to the mean of population 2.

As an example, we'll return to some data from Tutorial 2. This data has information about whether or not cities have right to work laws (RTWL), and their cost of living (COL). Here, we might be interested in whether the right to work law has an influence on cost of living. In this case, our null hypothesis ($H_0$) is that the mean COL is the same in cities with RTWL = 0 as in those with RTWL = 1.

In this case, it is important to note that the 2 populations of cities are *independent* of each other. That is, the cities with no RTWL are different from the cities that have a RTWL.

To test our $H_0$, we'll compute a "standardized difference", or **t statistic**, between the *sample mean* COL of the cities with RTWL=0 and the *sample mean* COL of the cities with RTWL=1. Once we compute this t, we can decide if it's "large" (e.g., t < -2 or t > 2) to determine if we can reject our $H_0$. For now, you don't have to worry much about these details; we'll cover them in the first few classes!

### Exploring the data

Let's start by reading in our data:

```{r load_d0}
d0 = read.csv("http://www.ilr.cornell.edu/~hadi/RABE4/Data4/P005.txt", sep='\t')
str(d0)
head(d0)
```

Now we'll plot the data to see the relationship between RTWL and COL:

```{r plot_col_on_rtwl, fig.width=4, fig.height=3}
boxplot(COL ~ RTWL, col='yellow', 
        pch=23, 
        xlab = "RTWL", ylab = "COL",
        main='COL vs RTWL',
        data=d0)
```

### Short-form data for t.test()

Before we can run a t-test, we have to make some changes to the data. From looking at the data above, we can see that the dataframe d0 is in *long-form*; each variable is in a different column. This format is fine for `boxplot()` and `lm()`, but older functions like `t.test()` need the data in *short-form* with COL for cities with RTWL = 0 in one column, and COL for cities with RTWL = 1 in a 2nd column.

We'll make 2 variables by selecting **subsets** of the COL data, *conditional* on whether or not the cities have a RTWL. In R, the *brackets* (`[ ]`) let us select rows of a variable conditional on another variable. Here, we'll select the rows of COL where RTWL is equal to 0, or 1:

```{r subsetCOL_d0}
COL0 = d0$COL[d0$RTWL == 0]
COL1 = d0$COL[d0$RTWL == 1]
```

Now that the COL data is grouped into variables based on RTWL status, we can explore these variables quickly:

```{r explore_subsetCOL_d0}
str(COL0)
str(COL1)
```

Here, we see that there are 28 cities with RTWL=0, and 10 cities with RTWL=1.

### Running an Independent Samples t-test

Now that we have our data in the correct format, we can run a t-test testing the H0 that mean(COL0) = mean(COL1). Right now, we'll just assume that the two variances are equal.

```{r ttest_subsetCOL_d0}
res1 = t.test(COL0, COL1, var.equal = TRUE)
res1
```

### Testing for equal variance

Great! However, we automatically assumed that the variances were equal between the 2 groups of cities. We can use the **standard deviation** function `sd()` to estimate the standard deviation for these 2 groups:

```{r sd_subsetCOL_d0}
c(sd0 = sd(COL0), sd1 = sd(COL1))
```

These numbers are pretty different; however, the two groups had different numbers of cities. We can use the `var.test()` function to directly test the H0 that the variance between two samples is equal.

```{r vartest_subsetCOL_d0}
var.test(COL0, COL1)
```

Here, we cannot reject the null because the two variances are not significantly different from each other (*p* = 0.5063).

### Running a Paired t-test

Suppose the COL measurements for RTWL=0 and RTWL=0 had been taken from the *same* cities. That is, the COL when RTWL=0 is from *before* the law was passed; the COL when RTWL=1 is from *after* the law was passed. Now, the samples would NOT be independent. Instead, the COL when RTWL=1 in city A is *dependent* on COL when RTWL=0. In this case, the two samples are *paired*. **Is COL influenced by RTWL?**

As an example, we have a study in which, for each city, COL is measured BEFORE the RTWL is passed, and 2 years AFTER the RTWL is passed:

```{r load_d0s}
d0s = read.csv('http://stanford.edu/class/psych252/data/rtwl.paired.csv')
str(d0s)
```

Since the two groups are **paired** (i.e., NOT independent), we must specify that in the `t.test()` by saying "`paired=TRUE`". Otherwise, our results will be incorrect.

```{r ttest_d0s}
res2a = t.test(d0s$col0, d0s$col1, 
               var.equal = TRUE, 
               paired = TRUE)
res2a
```

If we made a mistake and forgot to specify "`paired=TRUE`", R would default to `paired=FALSE`, and our output would be incorrect:

```{r ttest_incorr_d0s}
res2b = t.test(d0s$col0, d0s$col1, 
               var.equal = TRUE)
res2b
```

Here, the difference is not quite significant! So it's important you tell R that the groups are paired when the two samples are dependent on one another!

### Generate boxplots from short-form data

Now let's take a quick peek at this data. Since d0s is in short-form, we need to make some changes before boxplot can generate a plot for us. We'll start by making a variable by combining the data in the variable d0s$col0 with the data in d0s$col1:

```{r combine_cols_d0s}
col = c(d0s$col0, d0s$col1)
col
```

Then, we'll use the `rep()` (short for "repeat") function to make a long vector of 0s and 1s signifying RTWL status. Each vector should be 14 numbers long, since there were 14 cities total:

```{r rep_rtwl_d0s}
rtwl = rep(c(0, 1), each = 14)
rtwl
```

Now, we'll combine these variables to make a dataframe; there will be 2 variables, *(1)* the cost of living for the 14 cities before & after the RTWL was passed, and *(2)* the status of the RTWL:

```{r create_d0l}
d0l = data.frame(cbind(col = col, rtwl = rtwl))
d0l
```

Finally,  we can create a boxplot:

```{r plot_col_on_rtwl_paired, fig.width=4, fig.height=3}
boxplot(col ~ rtwl, col='lightgreen', 
        pch=23, 
        xlab = "RTWL", ylab = "COL",
        main='COL vs RTWL, paired data',
        data=d0l)
```

Additive & Interactive Models
-----------------------------------

Returning to the initial data, d0, we saw that COL depends on RTWL. Does it also depend on Income? To get a general idea, we can look at the data by plotting income and COL, as well as the linear line of best fit in red:

```{r plot_col_on_income, fig.width=4, fig.height=3}
plot(COL~Income, data=d0)
abline(lm(COL~Income, data=d0), col='red')
```

Now, we might be interested in the how the effect of RTWL on COL is related to Income level. In an **additive model** (e.g., `COL ~ RTWL + Income`), the effect of RTWL on COL is assumed to be the same at all levels of Income. Here, if income level were tightly correlated with whether or not cities have a RTWL, the unique variance explained by RTWL and Income level might be small. 

In contrast, in an **interactive model** (e.g., `COL ~ RTWL * Income`) the effect of RTWL on COL is **NOT** assumed to be the same at all levels of Income. Here, the RTWL could be positively correlated with COL at low incomes, but negatively correlated at high incomes.

### Treating income as a categorical variable

For simplicity, we might want to look at income as a categorical **factor**, not a quantitative variable. So let us replace Income by a new factor, "Incomecat" which can be 'low' or 'high'. We'll use an income of 4000 as the dividing point; those cities with incomes less than 4000 will fall into the "low" income category, and those with incomes at 4000 or above will fall into the "high" income category:

```{r incomecat_d0}
d0$Incomecat = findInterval(d0$Income, 4000)
d0$Incomecat = factor(d0$Incomecat, labels = c("low", "high"))
```

Now we'll print a *cross-tabulation* of RTWL and Incomecat to get an idea of how many cities fall into each group:

```{r crosstab_d0}
table(d0$Incomecat, d0$RTWL)
```

Note that there are only 2 cities with RTWL = 1 and Incomecat = high....so the following results are suspect. We'll continue though, just to demonstrate how to conduct these models.

### Additive model

```{r lm_add_d0}
res3 = lm(COL ~ RTWL + Incomecat, data = d0)
summary(res3)
```

### Interactive model

```{r lm_inter_d0}
res4 = lm(COL ~ RTWL * Incomecat, data = d0)
summary(res4)
```

Here we can see that the interaction is significant. To get a better idea for the data, we can use the `interaction.plot()` function to plot COL by RTWL and Income category:

```{r plot_rtwl_income_col_interaction, fig.width=4, fig.height=3}
with(d0, interaction.plot(RTWL, Incomecat, COL, 
                          fun = mean, 
                          xlab='RTWL', 
                          ylab='COL', 
                          lwd = 2))
```

By looking at this plot, we can see that when the income is high, the effect of RTWL on COL is small. However, when income is low, cost of living is lower if there is a right to work law.


Exploring Repeated Measures Exercise Data
-----------------------------------------

Here, we'll start by loading in the packages we introduced in lecture 2:

```{r load_ggplot_reshape}
library(ggplot2)
library(reshape2)
```

### Running a source file

Next, we're going to run a source file `mc.plots1.r` to change around some plotting parameters, including loading in the 'grid' package. Calling `source()` runs all the code in the .R file.


```{r source_plots1}
source('http://stanford.edu/class/psych252/tutorials/mc.plots1.r')
```

### Exercise data

Now, we'll load in the data file `exer.csv`. Here, participants (*n* = 30) were randomly assigned to two different diets: low-fat (`diet` = 1) and not low-fat (`diet` = 2), and three different types of exercise: at rest (`exertype` = 1), walking leisurely (`exertype` = 2), and running (`exertype` = 3).  Their pulse rate (`pulse`) was measured at three different time points during their assigned exercise: at 1 minute (`time` = 1), 15 minutes (`time` = 2), and 30 minutes (`time` = 3).  This is a *repeated measures* design, with `time` as the *within-subject* (repeated) variable.  **How does pulse depend on time, diet and exertype?**


```{r load_d2}
d2 <- read.csv('http://stanford.edu/class/psych252/data/exer.csv')
str(d2)
summary(d2)
```

We can see that all the variables are integers since the raw data entries began with numbers, even though some should be factors. We want to convert `id`, `diet`, and `exertype` to factors with informative levels:

```{r setfactors_d2}
d2$diet <- factor(d2$diet, labels=c('lo.fat','non.lo.fat'))
d2$id <- factor(d2$id)
d2$exertype <- factor(d2$exertype, labels=c('rest','walk','run'))

summary(d2) # double check formatting
```

### Plot exercise data
Now, we'll use `ggplot2`'s `qplot()` function to plot the subjects' pulse over time points 1-3 for each of the 6 groups (diet type X exercise type):

```{r qplot_tim_on_pulse_facets, fig.width=7, fig.height=5}
qp3 = qplot(time, pulse, facets = diet ~ exertype, colour = id,
            geom = "line", data=d2) + 
      theme_bw() + plot.style
print(qp3)
```

### Bar graphs

We might also want to visualize this data in bar graph form. To do this with ggplot, we'll use the `aggregate()` function to get means and standard errors from the data.

First, we'll extract the mean pulses across subjects for each of the 6 groups at all three time points:

```{r means_d2}
ms <- aggregate(pulse ~ time + diet + exertype, d2, mean)
ms
```

Now, we'll get the standard error of the mean. We'll do this using the function `se.mean()` defined in the script 'mc.plots1.r'. The function is elaborated below:

```{r sterr_d2}
ms$err = aggregate(pulse ~ time + diet + exertype, d2, 
                    FUN = se.mean)$pulse

# This is the same as the function se.mean()
ms$err = aggregate(pulse ~ time + diet + exertype, d2, 
                   function(x) {sd(x) / sqrt(length(x))})$pulse

ms
```

Finally, we plot the bar graph:
```{r qlot_time_on_pulse_facet_bars, fig.width=7, fig.height=5}
qp4 <- qplot(time, pulse, facets = . ~ diet, ymin=pulse - err, ymax=pulse + err, 
  geom=c("pointrange","line"), colour=exertype, data=ms) + 
	theme_bw() + plot.style
print(qp4)
```
